自动机器学习技术AutoML: 数据处理、特征工程、模型、优化算法等流程自动流水线化
自动神经网络结构搜索技术NAS: 拓扑超参优化；优化目标-网络性能、搜索时间；搜索空间，搜索策略，性能评估策略；
1.	性能评估策略：不仅取决于网络结构，还取决于训练效果（同一个网络学习参数的好坏）；计算量过大——条件松弛；更少的epochs（但不同结构的网络高效的时期不同）、数据精炼（均匀覆盖、难例提取）、迁移学习、数据样本本身的缩放。评估指标：正确率、参数数量、FLOPs、推理延时、计算强度、内存占用、功耗。多目标帕累托最优-非劣解集
2.	时间性能：真实时延（在机器上的运行时间）-不便——>时延预测（拆解成kernel size, stride for convolution, expansion ratio）
3.	网络结构编码参数化，包括算子、cell连接；channel未加入
4.	参数共享
5.	一次训练：交替训练-网络结构和网络权重交替更新造成偏差——>One Shot，Supernet只做一次训练
二、搜索算法（优化）：随机搜索baseline、贪婪搜索、
1.	贪婪算法：渐进增加分支，每一步都选择最好的K个模型进行训练，对早期的错误没有修正能力
2.	进化算法：空间内直接搜索
3.	强化学习：序列模型action-链接下一cell，网络模型结构参数化、连续化。State：当前网络结构；action：输出下一层的算子；return：性能评估指标
4.	贝叶斯优化：估计目标函数的分布

存在问题：自动数据标签标注，训练量过大，基于梯度的方法需要参数连续化
 

2019-7-3:



#### 1. 正则化

- LayerNorm:
  $$
  y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta
  $$
  

#### 2. softmax

![image-20220517170329898](C:\Users\zhaosida\AppData\Roaming\Typora\typora-user-images\image-20220517170329898.png)

减去最大值：计算稳定性